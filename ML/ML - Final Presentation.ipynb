{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e776f7e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/xampp/htdocs/SE J COMP\\connection.php\n",
      "C:/xampp/htdocs/SE J COMP\\failure.html\n",
      "C:/xampp/htdocs/SE J COMP\\first_page.html\n",
      "C:/xampp/htdocs/SE J COMP\\input.csv\n",
      "C:/xampp/htdocs/SE J COMP\\login.css\n",
      "C:/xampp/htdocs/SE J COMP\\login.html\n",
      "C:/xampp/htdocs/SE J COMP\\readoutput.php\n",
      "C:/xampp/htdocs/SE J COMP\\register.html\n",
      "C:/xampp/htdocs/SE J COMP\\SE J COMP - Shortcut.lnk\n",
      "C:/xampp/htdocs/SE J COMP\\second_page.html\n",
      "C:/xampp/htdocs/SE J COMP\\support.html\n",
      "C:/xampp/htdocs/SE J COMP\\upload.php\n",
      "C:/xampp/htdocs/SE J COMP\\validate.php\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import plotly.express as px\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected = True)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('C:/xampp/htdocs/SE J COMP'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f4bf716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ever_Married</th>\n",
       "      <th>Age</th>\n",
       "      <th>Graduated</th>\n",
       "      <th>Profession</th>\n",
       "      <th>Work_Experience</th>\n",
       "      <th>Spending_Score</th>\n",
       "      <th>Family_Size</th>\n",
       "      <th>Var_1</th>\n",
       "      <th>Segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>462809</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>462643</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Average</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Cat_4</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>466315</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>461735</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>67</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>High</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>462669</td>\n",
       "      <td>Female</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>High</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Cat_6</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  Gender Ever_Married  Age Graduated     Profession  Work_Experience  \\\n",
       "0  462809    Male           No   22        No     Healthcare              1.0   \n",
       "1  462643  Female          Yes   38       Yes       Engineer              NaN   \n",
       "2  466315  Female          Yes   67       Yes       Engineer              1.0   \n",
       "3  461735    Male          Yes   67       Yes         Lawyer              0.0   \n",
       "4  462669  Female          Yes   40       Yes  Entertainment              NaN   \n",
       "\n",
       "  Spending_Score  Family_Size  Var_1 Segmentation  \n",
       "0            Low          4.0  Cat_4            D  \n",
       "1        Average          3.0  Cat_4            A  \n",
       "2            Low          1.0  Cat_6            B  \n",
       "3           High          2.0  Cat_6            B  \n",
       "4           High          6.0  Cat_6            A  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/xampp/htdocs/SE J COMP/input.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc9258eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8068 entries, 0 to 8067\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ID               8068 non-null   int64  \n",
      " 1   Gender           8068 non-null   object \n",
      " 2   Ever_Married     7928 non-null   object \n",
      " 3   Age              8068 non-null   int64  \n",
      " 4   Graduated        7990 non-null   object \n",
      " 5   Profession       7944 non-null   object \n",
      " 6   Work_Experience  7239 non-null   float64\n",
      " 7   Spending_Score   8068 non-null   object \n",
      " 8   Family_Size      7733 non-null   float64\n",
      " 9   Var_1            7992 non-null   object \n",
      " 10  Segmentation     8068 non-null   object \n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 693.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c463b966",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1']\n",
    "numerical_features = ['Age', 'Work_Experience', 'Family_Size']\n",
    "\n",
    "to_drop = ['ID'] # contain unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac349cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import os\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9e02fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "path = '/working'\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # create directory to save label encoding models\n",
    "    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n",
    "        os.makedirs(os.path.join(path, \"TextEncoding\"))\n",
    "\n",
    "    # perform label encoding\n",
    "    le.fit(df[feature])\n",
    "    \n",
    "    # save the encoder\n",
    "    joblib.dump(le, open(os.path.join(path, \"TextEncoding/le_{}.sav\".format(feature)), 'wb'))\n",
    "    \n",
    "    # transfrom training data\n",
    "    df[feature] = le.transform(df[feature])\n",
    "\n",
    "    # get classes & remove first column to elude from dummy variable trap\n",
    "    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n",
    "    \n",
    "    # save classes\n",
    "    joblib.dump(columns, \n",
    "                open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c8243fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb637fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         variables       VIF\n",
      "0           Gender  2.172928\n",
      "1     Ever_Married  2.547924\n",
      "2        Graduated  2.526486\n",
      "3       Profession  2.365052\n",
      "4   Spending_Score  3.231881\n",
      "5  Work_Experience  1.546193\n",
      "6      Family_Size  3.222219\n"
     ]
    }
   ],
   "source": [
    "# Calculating VIF\n",
    "vif = pd.DataFrame()\n",
    "temp = df.dropna()\n",
    "vif[\"variables\"] = [feature for feature in categorical_features+numerical_features if feature not in ['Age', 'Var_1']]\n",
    "vif[\"VIF\"] = [variance_inflation_factor(temp[vif['variables']].values, i) for i in range(len(vif[\"variables\"]))]\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4344b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Ever_Married</th>\n",
       "      <td>1.735250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Graduated</th>\n",
       "      <td>0.966782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Profession</th>\n",
       "      <td>1.536936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Work_Experience</th>\n",
       "      <td>10.275161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Family_Size</th>\n",
       "      <td>4.152206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Var_1</th>\n",
       "      <td>0.941993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 missing %\n",
       "Ever_Married      1.735250\n",
       "Graduated         0.966782\n",
       "Profession        1.536936\n",
       "Work_Experience  10.275161\n",
       "Family_Size       4.152206\n",
       "Var_1             0.941993"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingValueFeatures = pd.DataFrame({'missing %': data.isnull().sum()*100/len(data)})\n",
    "missingValueFeatures[missingValueFeatures['missing %']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51bb80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_missing = data.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71acdbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 1.14, 'Work_Experience': 2.64, 'Family_Size': 1.2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of outliers present in each variable\n",
    "outlier_percentage = {}\n",
    "for feature in numerical_features:\n",
    "    tempData = data_missing.sort_values(by=feature)[feature]\n",
    "    Q1, Q3 = tempData.quantile([0.25, 0.75])\n",
    "    IQR = Q3 - Q1\n",
    "    Lower_range = Q1 - (1.5 * IQR)\n",
    "    Upper_range = Q3 + (1.5 * IQR)\n",
    "    outlier_percentage[feature] = round((((tempData<(Q1 - 1.5 * IQR)) | (tempData>(Q3 + 1.5 * IQR))).sum()/tempData.shape[0])*100,2)\n",
    "outlier_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c1e4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_missing.copy()\n",
    "path = '/working'\n",
    "for i, feature in enumerate(categorical_features):\n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "    # create directory to save label encoding models\n",
    "    if not os.path.exists(os.path.join(path, \"TextEncoding\")):\n",
    "        os.makedirs(os.path.join(path, \"TextEncoding\"))\n",
    "\n",
    "    # perform label encoding\n",
    "    le.fit(df[feature])\n",
    "    # save the encoder\n",
    "    joblib.dump(le, open(os.path.join(path, \"TextEncoding/le_{}.sav\".format(feature)), 'wb'))\n",
    "    \n",
    "    # transfrom training data\n",
    "    df[feature] = le.transform(df[feature])\n",
    "\n",
    "    # get classes & remove first column to elude from dummy variable trap\n",
    "    columns = list(map(lambda x: feature+' '+str(x), list(le.classes_)))[1:]\n",
    "    \n",
    "    # save classes\n",
    "    joblib.dump(columns, \n",
    "                open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'wb'))\n",
    "    # load classes\n",
    "    columns = joblib.load(\n",
    "        open(os.path.join(path, \"TextEncoding/le_{}_classes.sav\".format(feature)), 'rb'))\n",
    "\n",
    "    if len(le.classes_)>2:\n",
    "        # perform one hot encoding\n",
    "        ohe.fit(df[[feature]])\n",
    "        # save the encoder\n",
    "        joblib.dump(ohe, open(os.path.join(path, \"TextEncoding/ohe_{}.sav\".format(feature)), 'wb'))\n",
    "\n",
    "        # transfrom training data\n",
    "        # removing first column of encoded data to elude from dummy variable trap\n",
    "        tempData = ohe.transform(df[[feature]])[:, 1:]\n",
    "\n",
    "        # create Dataframe with columns as classes\n",
    "        tempData = pd.DataFrame(tempData, columns=columns)\n",
    "    else:\n",
    "        tempData = df[[feature]]\n",
    "    \n",
    "    # create dataframe with all the label encoded categorical features along with hot encoding\n",
    "    if i==0:\n",
    "        encodedData = pd.DataFrame(data=tempData, columns=tempData.columns.values.tolist())\n",
    "    else:\n",
    "        encodedData = pd.concat([encodedData, tempData], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5b7c3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6665 entries, 0 to 6664\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Age                       6665 non-null   int64  \n",
      " 1   Work_Experience           6665 non-null   float64\n",
      " 2   Family_Size               6665 non-null   float64\n",
      " 3   Segmentation              6665 non-null   object \n",
      " 4   Gender                    6665 non-null   int32  \n",
      " 5   Ever_Married              6665 non-null   int32  \n",
      " 6   Graduated                 6665 non-null   int32  \n",
      " 7   Profession Doctor         6665 non-null   float64\n",
      " 8   Profession Engineer       6665 non-null   float64\n",
      " 9   Profession Entertainment  6665 non-null   float64\n",
      " 10  Profession Executive      6665 non-null   float64\n",
      " 11  Profession Healthcare     6665 non-null   float64\n",
      " 12  Profession Homemaker      6665 non-null   float64\n",
      " 13  Profession Lawyer         6665 non-null   float64\n",
      " 14  Profession Marketing      6665 non-null   float64\n",
      " 15  Spending_Score High       6665 non-null   float64\n",
      " 16  Spending_Score Low        6665 non-null   float64\n",
      " 17  Var_1 Cat_2               6665 non-null   float64\n",
      " 18  Var_1 Cat_3               6665 non-null   float64\n",
      " 19  Var_1 Cat_4               6665 non-null   float64\n",
      " 20  Var_1 Cat_5               6665 non-null   float64\n",
      " 21  Var_1 Cat_6               6665 non-null   float64\n",
      " 22  Var_1 Cat_7               6665 non-null   float64\n",
      "dtypes: float64(18), int32(3), int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# merge numerical features and categorical encoded features\n",
    "df = df[numerical_features+['Segmentation']]\n",
    "df = pd.concat([df, encodedData], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0aba2d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a11eef14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features used-  ['Age', 'Work_Experience', 'Family_Size', 'Gender', 'Ever_Married', 'Graduated', 'Profession Doctor', 'Profession Engineer', 'Profession Entertainment', 'Profession Executive', 'Profession Healthcare', 'Profession Homemaker', 'Profession Lawyer', 'Profession Marketing', 'Spending_Score High', 'Spending_Score Low', 'Var_1 Cat_2', 'Var_1 Cat_3', 'Var_1 Cat_4', 'Var_1 Cat_5', 'Var_1 Cat_6', 'Var_1 Cat_7']\n"
     ]
    }
   ],
   "source": [
    "train_data = df.copy()\n",
    "feature_cols = [feature for feature in train_data.columns if feature not in(['Segmentation'])]\n",
    "print('features used- ', feature_cols)\n",
    "\n",
    "''' Rescaling to [0,1] '''\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train_data[feature_cols])\n",
    "train_data[feature_cols] = scaler.transform(train_data[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd09d2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Segmentation'] = train_data['Segmentation'].map({'A':0, 'B':1, 'C':2, 'D':3})\n",
    "X = train_data[feature_cols]\n",
    "y = train_data['Segmentation']\n",
    "\n",
    "validation_size = 0.50\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=validation_size, \n",
    "                                                    random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8509c207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df24178e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics...\n",
      "[[397 107 166 138]\n",
      " [215 193 287  91]\n",
      " [114 106 534 106]\n",
      " [167  45  45 621]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.49      0.47       808\n",
      "           1       0.43      0.25      0.31       786\n",
      "           2       0.52      0.62      0.56       860\n",
      "           3       0.65      0.71      0.68       878\n",
      "\n",
      "    accuracy                           0.52      3332\n",
      "   macro avg       0.51      0.52      0.51      3332\n",
      "weighted avg       0.51      0.52      0.51      3332\n",
      "\n",
      "Validation metrics...\n",
      "[[406 106 144 152]\n",
      " [251 152 295  88]\n",
      " [103  96 555 106]\n",
      " [190  37  48 604]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.50      0.46       808\n",
      "           1       0.39      0.19      0.26       786\n",
      "           2       0.53      0.65      0.58       860\n",
      "           3       0.64      0.69      0.66       879\n",
      "\n",
      "    accuracy                           0.52      3333\n",
      "   macro avg       0.50      0.51      0.49      3333\n",
      "weighted avg       0.50      0.52      0.50      3333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train)\n",
    "\n",
    "print('Train metrics...')\n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Validation metrics...')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b84fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' metrics on original data '''\n",
    "y_pred = model.predict(train_data[feature_cols])\n",
    "\n",
    "# def make_cm(matrix, columns):\n",
    "#     n = len(columns)\n",
    "#     act = ['actual Segmentation'] * n\n",
    "#     pred = ['predicted Segmentation'] * n\n",
    "\n",
    "#     cm = pd.DataFrame(matrix, \n",
    "#         columns=[pred, columns], index=[act, columns])\n",
    "#     return cm\n",
    "\n",
    "# df_matrix=make_cm(\n",
    "#     confusion_matrix(train_data['Segmentation'], y_pred),['A', 'B', 'C', 'D'])\n",
    "\n",
    "# display(df_matrix)\n",
    "# print(classification_report(train_data['Segmentation'], y_pred))\n",
    "y_pred\n",
    "a = 0\n",
    "b = 0\n",
    "c = 0\n",
    "d = 0\n",
    "for i in y_pred:\n",
    "    if i == 0:\n",
    "        a = a+1\n",
    "    elif i == 1:\n",
    "        b = b+1\n",
    "    elif i == 2:\n",
    "        c = c+1\n",
    "    elif i == 3:\n",
    "        d = d+1\n",
    "a = str(a)\n",
    "b = str(b)\n",
    "c = str(c)\n",
    "d = str(d)\n",
    "\n",
    "lst = [a, b, c, d]\n",
    "lst\n",
    "file = open('output.csv', 'w+', newline = '')\n",
    "with file:\n",
    "    write = csv.writer(file)\n",
    "    write.writerow(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d98514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71831efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
